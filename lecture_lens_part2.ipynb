{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":235393357,"sourceType":"kernelVersion"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:28:37.565712Z","iopub.execute_input":"2025-06-23T10:28:37.565899Z","iopub.status.idle":"2025-06-23T10:28:38.900435Z","shell.execute_reply.started":"2025-06-23T10:28:37.565882Z","shell.execute_reply":"2025-06-23T10:28:38.899668Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-hackathon/__results__.html\n/kaggle/input/llm-hackathon/__notebook__.ipynb\n/kaggle/input/llm-hackathon/__output__.json\n/kaggle/input/llm-hackathon/custom.css\n/kaggle/input/llm-hackathon/output/stable_diffusion/presentation_data/Stable Diffusion_content.json\n/kaggle/input/llm-hackathon/output/stable_diffusion/final_notes/19853_shylaja.sharath_31_20250327084200249_Video_ENC_notes.md\n/kaggle/input/llm-hackathon/output/stable_diffusion/final_notes/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1)_notes.md\n/kaggle/input/llm-hackathon/output/stable_diffusion/transcripts/19853_shylaja.sharath_31_20250327084200249_Video_ENC.txt\n/kaggle/input/llm-hackathon/output/stable_diffusion/transcripts/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1).txt\n/kaggle/input/llm-hackathon/output/stable_diffusion/audio/19853_shylaja.sharath_31_20250327084200249_Video_ENC.wav\n/kaggle/input/llm-hackathon/output/stable_diffusion/audio/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1).wav\n/kaggle/input/llm-hackathon/output/Lora&Qlora/presentation_data/Finetuning_content.json\n/kaggle/input/llm-hackathon/output/Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318121200085_Video_ENC (1)_notes.md\n/kaggle/input/llm-hackathon/output/Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318125700082_Video_ENC_notes.md\n/kaggle/input/llm-hackathon/output/Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318112700094_Video_ENC (1)_notes.md\n/kaggle/input/llm-hackathon/output/Lora&Qlora/transcripts/19853_shylaja.sharath_31_20250318112700094_Video_ENC (1).txt\n/kaggle/input/llm-hackathon/output/Lora&Qlora/transcripts/19853_shylaja.sharath_31_20250318121200085_Video_ENC (1).txt\n/kaggle/input/llm-hackathon/output/Lora&Qlora/transcripts/19853_shylaja.sharath_31_20250318125700082_Video_ENC.txt\n/kaggle/input/llm-hackathon/output/Lora&Qlora/audio/19853_shylaja.sharath_31_20250318112700094_Video_ENC (1).wav\n/kaggle/input/llm-hackathon/output/Lora&Qlora/audio/19853_shylaja.sharath_31_20250318121200085_Video_ENC (1).wav\n/kaggle/input/llm-hackathon/output/Lora&Qlora/audio/19853_shylaja.sharath_31_20250318125700082_Video_ENC.wav\n/kaggle/input/llm-hackathon/output/expn_tree/presentation_data/Class7_Unit3_Trees_ExprTree_content.json\n/kaggle/input/llm-hackathon/output/expn_tree/final_notes/7b_2020-09-25 12-12-37_ExprTReeCode 00_00_09-00_26_52_notes.md\n/kaggle/input/llm-hackathon/output/expn_tree/final_notes/7a_2020-09-24 09-28-52_ExprTreeCon_notes.md\n/kaggle/input/llm-hackathon/output/expn_tree/transcripts/7a_2020-09-24 09-28-52_ExprTreeCon.txt\n/kaggle/input/llm-hackathon/output/expn_tree/transcripts/7b_2020-09-25 12-12-37_ExprTReeCode 00_00_09-00_26_52.txt\n/kaggle/input/llm-hackathon/output/expn_tree/audio/7a_2020-09-24 09-28-52_ExprTreeCon.wav\n/kaggle/input/llm-hackathon/output/expn_tree/audio/7b_2020-09-25 12-12-37_ExprTReeCode 00_00_09-00_26_52.wav\n/kaggle/input/llm-hackathon/output/agentic/presentation_data/Agentic Workflow_content.json\n/kaggle/input/llm-hackathon/output/agentic/presentation_data/AutoGen CrewAI_content.json\n/kaggle/input/llm-hackathon/output/agentic/final_notes/19853_shylaja.sharath_31_20250401121200417_Video_ENC_notes.md\n/kaggle/input/llm-hackathon/output/agentic/transcripts/19853_shylaja.sharath_31_20250401121200417_Video_ENC.txt\n/kaggle/input/llm-hackathon/output/agentic/audio/19853_shylaja.sharath_31_20250401121200417_Video_ENC.wav\n/kaggle/input/llm-hackathon/output/Heap/presentation_data/Class8_Unit3_Trees_Heap_content.json\n/kaggle/input/llm-hackathon/output/Heap/final_notes/8b_2020-09-26 09-34-27_HeapCode 00_00_09-00_56_50_notes.md\n/kaggle/input/llm-hackathon/output/Heap/final_notes/8a_2020-09-24 13-07-04_HeapCon 00_00_01-00_42_121_notes.md\n/kaggle/input/llm-hackathon/output/Heap/transcripts/8a_2020-09-24 13-07-04_HeapCon 00_00_01-00_42_121.txt\n/kaggle/input/llm-hackathon/output/Heap/transcripts/8b_2020-09-26 09-34-27_HeapCode 00_00_09-00_56_50.txt\n/kaggle/input/llm-hackathon/output/Heap/audio/8b_2020-09-26 09-34-27_HeapCode 00_00_09-00_56_50.wav\n/kaggle/input/llm-hackathon/output/Heap/audio/8a_2020-09-24 13-07-04_HeapCon 00_00_01-00_42_121.wav\n/kaggle/input/llm-hackathon/output/BST/presentation_data/Class2_Unit3_Tree_BST_DynamicInsert_content.json\n/kaggle/input/llm-hackathon/output/BST/presentation_data/Class4_Unit3_Trees_BST_ArrayInsert_content.json\n/kaggle/input/llm-hackathon/output/BST/presentation_data/Class3_Unit3_Trees_BSTDeletion_content.json\n/kaggle/input/llm-hackathon/output/TBT/presentation_data/Class6_Unit3_Trees_ThreadBST_content.json\n/kaggle/input/llm-hackathon/output/TBT/final_notes/6b_2020-09-25 11-29-19_TBTCode 00_00_04-00_35_198_notes.md\n/kaggle/input/llm-hackathon/output/TBT/final_notes/6a_2020-09-22 09-49-32_TBTCon_notes.md\n/kaggle/input/llm-hackathon/output/TBT/transcripts/6b_2020-09-25 11-29-19_TBTCode 00_00_04-00_35_198.txt\n/kaggle/input/llm-hackathon/output/TBT/transcripts/6a_2020-09-22 09-49-32_TBTCon.txt\n/kaggle/input/llm-hackathon/output/TBT/audio/6b_2020-09-25 11-29-19_TBTCode 00_00_04-00_35_198.wav\n/kaggle/input/llm-hackathon/output/TBT/audio/6a_2020-09-22 09-49-32_TBTCon.wav\n/kaggle/input/llm-hackathon/output/Multimodal/presentation_data/MAMBA_content.json\n/kaggle/input/llm-hackathon/output/Multimodal/presentation_data/MultiModal LLMs_content.json\n/kaggle/input/llm-hackathon/output/Multimodal/final_notes/19853_shylaja.sharath_31_20250401112700078_Video_ENC_notes.md\n/kaggle/input/llm-hackathon/output/Multimodal/transcripts/19853_shylaja.sharath_31_20250401112700078_Video_ENC.txt\n/kaggle/input/llm-hackathon/output/Multimodal/audio/19853_shylaja.sharath_31_20250401112700078_Video_ENC.wav\n/kaggle/input/llm-hackathon/output/binary_tree_traversal/presentation_data/Class5_Unit3_BST_Traversal_content.json\n/kaggle/input/llm-hackathon/output/binary_tree_traversal/final_notes/5a_2020-09-15 09-04-51_BinTraversal_notes.md\n/kaggle/input/llm-hackathon/output/binary_tree_traversal/transcripts/5a_2020-09-15 09-04-51_BinTraversal.txt\n/kaggle/input/llm-hackathon/output/binary_tree_traversal/audio/5a_2020-09-15 09-04-51_BinTraversal.wav\n/kaggle/input/llm-hackathon/output/Tree_traversal/presentation_data/class9_Unit3_Trees_naryTraversal_content.json\n/kaggle/input/llm-hackathon/output/Tree_traversal/final_notes/9a_2020-09-16 09-46-13_TreeTravCon_notes.md\n/kaggle/input/llm-hackathon/output/Tree_traversal/transcripts/9a_2020-09-16 09-46-13_TreeTravCon.txt\n/kaggle/input/llm-hackathon/output/Tree_traversal/audio/9a_2020-09-16 09-46-13_TreeTravCon.wav\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Step 7.1 (Gemini): Install google-generativeai Library and Initialize Client\n\nimport os\nimport subprocess\nimport json\nfrom pathlib import Path\nimport time\nimport gc\n\n# 1. Install Google Generative AI Python library\nprint(\"Installing google-generativeai library...\")\n# Use --upgrade to ensure we get a recent version\ninstall_gemini_lib = subprocess.run(['pip', 'install', '-q', '--upgrade', 'google-generativeai'], capture_output=True, text=True)\n\nif install_gemini_lib.returncode == 0:\n    print(\"google-generativeai library installed/upgraded successfully.\")\nelse:\n    print(\"Error installing google-generativeai library:\")\n    print(install_gemini_lib.stderr)\n    raise RuntimeError(\"Failed to install google-generativeai library.\")\n\n# Import AFTER installation\ntry:\n    import google.generativeai as genai\n    from google.generativeai.types import HarmCategory, HarmBlockThreshold # For safety settings\n    from kaggle_secrets import UserSecretsClient\nexcept ImportError as e:\n    print(f\"Failed to import libraries: {e}. Please ensure installation was successful.\")\n    raise\n\n# 2. Access API Key from Kaggle Secrets and Configure SDK\ngoogle_api_key = None\ntry:\n    user_secrets = UserSecretsClient()\n    google_api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\n    if not google_api_key:\n        print(\"ERROR: Google API Key not found in Kaggle Secrets.\")\n        print(\"Please ensure you added a secret with the label 'GOOGLE_API_KEY'.\")\n    else:\n        print(\"Google API Key retrieved successfully.\")\n        genai.configure(api_key=google_api_key)\n        print(\"Gemini SDK configured.\")\n\nexcept Exception as e:\n    print(f\"Error accessing Kaggle Secrets or configuring Gemini SDK: {e}\")\n    print(\"Ensure Kaggle Secrets are properly configured and the key label is 'GOOGLE_API_KEY'.\")\n\n# 3. Define LLM Model to use - GEMINI 1.5 PRO LATEST\n# *********************************************************************\n# Switching to Gemini 1.5 Pro for its large context window\n# Model ID might change, check Google AI documentation if this exact ID fails\nllm_model_name = \"gemini-1.5-flash-latest\"\n# *********************************************************************\nprint(f\"Using LLM model: {llm_model_name}\")\n\n# Initialize the GenerativeModel instance\nmodel = None\nif google_api_key: # Only proceed if key was retrieved\n    try:\n        # You can adjust safety settings and generation config here if needed\n        model = genai.GenerativeModel(\n            llm_model_name,\n            # Example: Setting safety thresholds lower (use with caution)\n            # safety_settings={\n            #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n            #     HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n            #     HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n            #     HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n            # }\n            # generation_config=genai.types.GenerationConfig(temperature=0.7)\n            )\n        print(f\"GenerativeModel instance created for {llm_model_name}.\")\n    except Exception as e:\n        print(f\"Error creating GenerativeModel instance: {e}\")\n\n\n# Define output_base_path (as it might have been cleared if kernel restarted)\noutput_base_path = Path(\"/kaggle/working/output\")\noutput_base_path.mkdir(parents=True, exist_ok=True)\nprint(f\"Output base path set to: {output_base_path}\")\n\n# --- Status Check ---\nif model:\n    print(f\"\\nSetup complete. Ready for note generation with {llm_model_name}.\")\n    # Because Gemini 1.5 Pro has a large context window (1M+ tokens),\n    # we will likely NOT need transcript chunking or presentation summarization.\n    print(\"Chunking/summarization steps will be removed in the next cells.\")\nelse:\n    print(\"\\nSetup failed (API key or model initialization issue). Cannot proceed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:48:40.888375Z","iopub.execute_input":"2025-06-23T10:48:40.888871Z","iopub.status.idle":"2025-06-23T10:48:43.833600Z","shell.execute_reply.started":"2025-06-23T10:48:40.888849Z","shell.execute_reply":"2025-06-23T10:48:43.832993Z"}},"outputs":[{"name":"stdout","text":"Installing google-generativeai library...\ngoogle-generativeai library installed/upgraded successfully.\nGoogle API Key retrieved successfully.\nGemini SDK configured.\nUsing LLM model: gemini-1.5-flash-latest\nGenerativeModel instance created for gemini-1.5-flash-latest.\nOutput base path set to: /kaggle/working/output\n\nSetup complete. Ready for note generation with gemini-1.5-flash-latest.\nChunking/summarization steps will be removed in the next cells.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Step 7.2 - Cell 1 (Enhanced for Gemini): Helper Functions & Prompt\n\nimport json\nfrom pathlib import Path\nimport time\nimport gc\n# Requires google.generativeai as genai (imported in 7.1)\n# Assumes 'model' (the genai.GenerativeModel instance), 'llm_model_name',\n# 'output_base_path' are defined from Step 7.1 (Gemini version).\n\n# --- Helper Function to Format Presentation JSON ---\ndef format_presentation_data(data):\n    \"\"\"Converts presentation JSON data into a readable string for the LLM.\"\"\"\n    if not data or (\"error\" in data):\n        return \"No presentation data available or there was an error processing it.\\n\"\n\n    output = f\"--- Presentation Content ({data.get('file_type', 'N/A')}: {data.get('source_file', 'N/A')}) ---\\n\\n\"\n    if data.get('file_type') == 'pptx':\n        slides = data.get('slides')\n        if not slides: return output + \"No slides found or extracted.\\n\"\n        for slide in slides:\n            slide_num = slide.get('slide_number', '?')\n            output += f\"## Slide {slide_num}\\n\"\n            if slide.get('title'): output += f\"### Title: {slide['title']}\\n\"\n            if slide.get('content'):\n                output += \"Content:\\n\"\n                if isinstance(slide['content'], list):\n                    for line in slide['content']: output += f\"{line}\\n\"\n                else: output += f\"{str(slide['content'])}\\n\"\n            if slide.get('notes'): output += f\"Presenter Notes: {slide['notes']}\\n\"\n            output += \"\\n\"\n    elif data.get('file_type') == 'pdf':\n        pages = data.get('pages')\n        if not pages: return output + \"No pages found or extracted.\\n\"\n        for page in pages:\n            page_num = page.get('page_number', '?')\n            output += f\"## Page {page_num}\\n\"\n            if page.get('text'): output += f\"Text:\\n{page['text']}\\n\"\n            output += \"\\n\"\n    else: output += f\"Unknown presentation format: {data.get('file_type', 'N/A')}.\\n\"\n    output += \"--- End of Presentation Content ---\\n\"\n    return output\n\n# --- Helper Function to Chunk Text ---\ndef chunk_text(text, max_tokens_per_chunk=8000, overlap_tokens=200):\n    \"\"\"Split text into overlapping chunks for processing.\"\"\"\n    # Simple word-based chunking (approximate)\n    words = text.split()\n    words_per_token = 0.75  # Approximate ratio\n    max_words_per_chunk = int(max_tokens_per_chunk * words_per_token)\n    overlap_words = int(overlap_tokens * words_per_token)\n    \n    chunks = []\n    start = 0\n    \n    while start < len(words):\n        end = min(start + max_words_per_chunk, len(words))\n        chunk = ' '.join(words[start:end])\n        chunks.append(chunk)\n        \n        if end >= len(words):\n            break\n            \n        start = end - overlap_words\n    \n    return chunks\n\n# --- Enhanced LLM Prompt Template ---\nprompt_template = \"\"\"\nYou are an expert AI assistant tasked with creating comprehensive, well-structured lecture notes.\nYou will be given the **full transcript** of a spoken lecture and the **full content** of the accompanying presentation slides (or PDF pages).\nYour goal is to synthesize information from BOTH sources to generate high-quality academic notes optimized for student learning and review.\n\n**Instructions:**\n\n1. **Analyze Both Inputs:** Carefully read the provided Lecture Transcript and Presentation Content.\n\n2. **Synthesize Information:** Combine relevant information from the transcript and presentation. Integrate ideas rather than copying. Use the presentation structure as a foundation, but enrich with details, explanations, and examples from the transcript.\n\n3. **Structure Requirements:**\n   * **Title:** Start with `# Lecture Notes: [Topic/Title from content]`\n   * **Main Sections:** Use `##` for primary topics and major concepts\n   * **Subsections:** Use `###` for subtopics, specific methods, procedures, or detailed concepts\n   * **Content Organization:** Use bullet points (`*`) for key details, definitions, examples, and supporting information\n   * **Emphasis:** Use `**bold text**` for important keywords, concepts, definitions, formulas, and key terms\n   * **Code/Algorithms:** Use code blocks when showing algorithms, formulas, or structured procedures\n   * **Examples:** Create dedicated example sections when demonstrating concepts\n\n4. **Content Organization Principles:**\n   * **Lead with Definitions:** Start major concepts with clear, complete definitions\n   * **Logical Progression:** Organize content from fundamental concepts to applications\n   * **Method Separation:** Create distinct sections for different approaches, methods, or procedures\n   * **Property Grouping:** List important characteristics and properties as organized bullet points\n   * **Step-by-Step Clarity:** Break down complex processes into clear, numbered or bulleted steps\n   * **Integration:** Weave transcript elaborations naturally into slide-based structure\n\n5. **Content Guidelines:**\n   * **Completeness:** Include all significant concepts mentioned in either source\n   * **Definitions:** Provide precise, academic definitions for key terms\n   * **Examples:** Include concrete examples with step-by-step demonstrations when provided\n   * **Analysis:** Add complexity analysis, efficiency discussions, or comparative analysis when mentioned\n   * **Context:** Include background information and applications discussed in the transcript\n   * **Clarifications:** Use transcript content to clarify or expand on slide points\n\n6. **Formatting Standards:**\n   * Use consistent indentation for nested bullet points\n   * Maintain parallel structure in lists and sections\n   * Include mathematical notation, formulas, or technical syntax using appropriate markdown\n   * Separate major sections with clear spacing\n   * Use descriptive, informative section headers\n   * Create logical flow between related concepts\n\n7. **Quality Requirements:**\n   * **Academic Tone:** Maintain formal, precise academic language\n   * **Comprehensiveness:** Include sufficient detail for thorough understanding\n   * **Clarity:** Make complex concepts accessible to students\n   * **Structure:** Ensure logical organization that supports learning\n   * **Integration:** Seamlessly combine slide and transcript information\n   * **Exam-Ready:** Provide the level of detail needed for assessment preparation\n\n8. **Adaptive Structure:** Let the content determine the specific sections, but commonly include:\n   * Fundamental definitions and concepts\n   * Key properties or characteristics  \n   * Different methods, approaches, or types\n   * Detailed examples and applications\n   * Comparative analysis or efficiency discussions\n   * Summary of key takeaways\n\n**Input Data:**\n\n{presentation_content}\n\n**Full Lecture Transcript:**\n\n```text\n{transcript_text}\n```\n\nGenerate comprehensive lecture notes in Markdown format following the above structure and requirements. Adapt the section organization to best fit the content while maintaining academic rigor and clarity. Start directly with the lecture title - no introductory text.\n\"\"\"\n\n# --- Enhanced Gemini API Function ---\ndef generate_notes_with_gemini(prompt_content, max_retries=2, initial_delay=5):\n    \"\"\"Calls the Gemini API using the initialized model, handles retries.\"\"\"\n    global model # Uses the genai.GenerativeModel instance from Step 7.1\n    if not model:\n        print(\"  Error: Gemini model not initialized.\")\n        return \"## Error: Gemini model not initialized.\"\n\n    delay = initial_delay\n    for attempt in range(max_retries + 1):\n        try:\n            # Make the API call with enhanced configuration\n            response = model.generate_content(\n                prompt_content,\n                generation_config={\n                    \"temperature\": 0.3,  # Lower temperature for more structured output\n                    \"top_p\": 0.9,\n                    \"top_k\": 40,\n                    \"max_output_tokens\": 8192,  # Increased for comprehensive notes\n                }\n            )\n\n            # Process the response\n            if not response.candidates:\n                block_reason = \"Unknown\"\n                try:\n                    block_reason = response.prompt_feedback.block_reason\n                except Exception:\n                    print(\"  Warning: Could not retrieve block_reason from prompt_feedback.\")\n\n                print(f\"  Warning: Call blocked by safety settings (Reason: {block_reason}). Attempt {attempt + 1}/{max_retries + 1}.\")\n                if attempt < max_retries:\n                    print(f\"   Retrying in {delay} seconds...\")\n                    time.sleep(delay)\n                    delay *= 2\n                    continue\n                else:\n                    return f\"## Error: Content generation blocked by safety settings (Reason: {block_reason}).\"\n\n            # Check if response text is usable\n            response_text = \"\"\n            try:\n                response_text = response.text\n            except ValueError:\n                print(f\"  Warning: ValueError accessing response.text. Prompt feedback: {response.prompt_feedback}\")\n                response_text = \"\"\n\n            if response_text and isinstance(response_text, str) and response_text.strip():\n                return response_text # Success\n            else:\n                print(f\"  Warning: Received empty text content from Gemini (Attempt {attempt + 1}/{max_retries + 1}).\")\n                try:\n                    print(f\"     Prompt Feedback: {response.prompt_feedback}\")\n                except Exception:\n                    print(\"     Could not retrieve prompt feedback.\")\n\n                if attempt < max_retries:\n                    print(f\"   Retrying in {delay} seconds...\")\n                    time.sleep(delay)\n                    delay *= 2\n                    continue\n                else:\n                    return \"## Error: Received empty response from Gemini.\"\n\n        except Exception as e:\n            print(f\"  Error during Gemini API call (Attempt {attempt + 1}/{max_retries + 1}): {type(e).__name__} - {e}\")\n            if attempt < max_retries:\n                print(f\"   Retrying in {delay} seconds...\")\n                time.sleep(delay)\n                delay *= 2\n                continue\n            else:\n                print(f\"  Failed after {max_retries} retries.\")\n                return f\"## Error: API call failed after retries ({type(e).__name__}).\"\n\n    return \"## Error: Failed to generate notes after multiple retries.\"\n\n# --- Chunked Processing Function ---\ndef generate_notes_with_chunking(transcript_text, formatted_presentation, lecture_title):\n    \"\"\"Generate notes using chunking approach for very long content.\"\"\"\n    print(\"    Using chunked processing for long content...\")\n    \n    # Generate outline first\n    outline_prompt = f\"\"\"\nBased on this lecture content, create an outline of 4-8 main sections for comprehensive lecture notes.\n\n**LECTURE:** {lecture_title}\n\n**SLIDES:**\n{formatted_presentation[:3000]}\n\n**TRANSCRIPT EXCERPT:**\n{transcript_text[:8000]}\n\nProvide ONLY a numbered list of section titles that cover the main topics discussed. Each title should be clear and descriptive.\nFormat: \n1. Section Title One\n2. Section Title Two\netc.\n\"\"\"\n    \n    outline_response = generate_notes_with_gemini(outline_prompt)\n    if outline_response.startswith(\"## Error:\"):\n        return outline_response\n    \n    # Parse section titles\n    section_titles = []\n    for line in outline_response.split('\\n'):\n        line = line.strip()\n        if line and any(char.isdigit() for char in line[:3]):\n            # Remove numbering and extract title\n            title = line.split('. ', 1)[-1] if '. ' in line else line\n            section_titles.append(title)\n    \n    if not section_titles:\n        return \"## Error: Could not generate valid section outline.\"\n    \n    # Chunk the transcript\n    transcript_chunks = chunk_text(transcript_text, max_tokens_per_chunk=8000, overlap_tokens=200)\n    print(f\"      Transcript split into {len(transcript_chunks)} chunks for {len(section_titles)} sections.\")\n    \n    # Generate content for each section\n    all_sections = []\n    chunk_per_section = max(1, len(transcript_chunks) // len(section_titles))\n    \n    for i, section_title in enumerate(section_titles):\n        start_chunk = min(i * chunk_per_section, len(transcript_chunks) - 1)\n        end_chunk = min(start_chunk + chunk_per_section + 1, len(transcript_chunks))\n        section_transcript = \"\\n\\n\".join(transcript_chunks[start_chunk:end_chunk])\n        \n        section_prompt = f\"\"\"\nCreate detailed content for this section of lecture notes:\n\n**SECTION:** {section_title}\n**LECTURE:** {lecture_title}\n\n**RELEVANT TRANSCRIPT:**\n{section_transcript[:12000]}\n\n**SLIDES FOR REFERENCE:**\n{formatted_presentation[:2000]}\n\nGenerate comprehensive content for this section using the formatting requirements:\n- Use ### for the section header: ### {section_title}\n- Use **bold** for key terms and concepts\n- Use * for bullet points with important details\n- Include definitions, examples, and explanations\n- Maintain academic tone and structure\n\nFocus only on content relevant to this section.\n\"\"\"\n        \n        section_response = generate_notes_with_gemini(section_prompt)\n        if not section_response.startswith(\"## Error:\"):\n            all_sections.append(section_response)\n        else:\n            all_sections.append(f\"### {section_title}\\n\\n*Error generating content for this section.*\")\n    \n    # Combine all sections\n    lecture_title_clean = lecture_title.replace('_', ' ').title()\n    combined_notes = f\"# Lecture Notes: {lecture_title_clean}\\n\\n\"\n    combined_notes += \"\\n\\n\".join(all_sections)\n    \n    return combined_notes\n\nprint(\"Enhanced helper functions and prompt template defined for Gemini.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:48:49.361296Z","iopub.execute_input":"2025-06-23T10:48:49.361991Z","iopub.status.idle":"2025-06-23T10:48:49.381424Z","shell.execute_reply.started":"2025-06-23T10:48:49.361963Z","shell.execute_reply":"2025-06-23T10:48:49.380756Z"}},"outputs":[{"name":"stdout","text":"Enhanced helper functions and prompt template defined for Gemini.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Step 7.2 - Cell 1 (Enhanced for Gemini): Helper Functions & Prompt\n\nimport json\nfrom pathlib import Path\nimport time\nimport gc\n# Requires google.generativeai as genai (imported in 7.1)\n# Assumes 'model' (the genai.GenerativeModel instance), 'llm_model_name',\n# 'output_base_path' are defined from Step 7.1 (Gemini version).\n\n# --- Helper Function to Format Presentation JSON ---\ndef format_presentation_data(data):\n    \"\"\"Converts presentation JSON data into a readable string for the LLM.\"\"\"\n    if not data or (\"error\" in data):\n        return \"No presentation data available or there was an error processing it.\\n\"\n\n    output = f\"--- Presentation Content ({data.get('file_type', 'N/A')}: {data.get('source_file', 'N/A')}) ---\\n\\n\"\n    if data.get('file_type') == 'pptx':\n        slides = data.get('slides')\n        if not slides: return output + \"No slides found or extracted.\\n\"\n        for slide in slides:\n            slide_num = slide.get('slide_number', '?')\n            output += f\"## Slide {slide_num}\\n\"\n            if slide.get('title'): output += f\"### Title: {slide['title']}\\n\"\n            if slide.get('content'):\n                output += \"Content:\\n\"\n                if isinstance(slide['content'], list):\n                    for line in slide['content']: output += f\"{line}\\n\"\n                else: output += f\"{str(slide['content'])}\\n\"\n            if slide.get('notes'): output += f\"Presenter Notes: {slide['notes']}\\n\"\n            output += \"\\n\"\n    elif data.get('file_type') == 'pdf':\n        pages = data.get('pages')\n        if not pages: return output + \"No pages found or extracted.\\n\"\n        for page in pages:\n            page_num = page.get('page_number', '?')\n            output += f\"## Page {page_num}\\n\"\n            if page.get('text'): output += f\"Text:\\n{page['text']}\\n\"\n            output += \"\\n\"\n    else: output += f\"Unknown presentation format: {data.get('file_type', 'N/A')}.\\n\"\n    output += \"--- End of Presentation Content ---\\n\"\n    return output\n\n# --- Helper Function to Chunk Text ---\ndef chunk_text(text, max_tokens_per_chunk=8000, overlap_tokens=200):\n    \"\"\"Split text into overlapping chunks for processing.\"\"\"\n    # Simple word-based chunking (approximate)\n    words = text.split()\n    words_per_token = 0.75  # Approximate ratio\n    max_words_per_chunk = int(max_tokens_per_chunk * words_per_token)\n    overlap_words = int(overlap_tokens * words_per_token)\n    \n    chunks = []\n    start = 0\n    \n    while start < len(words):\n        end = min(start + max_words_per_chunk, len(words))\n        chunk = ' '.join(words[start:end])\n        chunks.append(chunk)\n        \n        if end >= len(words):\n            break\n            \n        start = end - overlap_words\n    \n    return chunks\n\n# --- Enhanced LLM Prompt Template ---\nprompt_template = \"\"\"\nYou are an expert AI assistant tasked with creating comprehensive, well-structured lecture notes.\nYou will be given the **full transcript** of a spoken lecture and the **full content** of the accompanying presentation slides (or PDF pages).\nYour goal is to synthesize information from BOTH sources to generate high-quality academic notes optimized for student learning and review.\n\n**Instructions:**\n\n1. **Analyze Both Inputs:** Carefully read the provided Lecture Transcript and Presentation Content.\n\n2. **Synthesize Information:** Combine relevant information from the transcript and presentation. Integrate ideas rather than copying. Use the presentation structure as a foundation, but enrich with details, explanations, and examples from the transcript.\n\n3. **Structure Requirements:**\n   * **Title:** Start with `# Lecture Notes: [Topic/Title from content]`\n   * **Main Sections:** Use `##` for primary topics and major concepts\n   * **Subsections:** Use `###` for subtopics, specific methods, procedures, or detailed concepts\n   * **Content Organization:** Use bullet points (`*`) for key details, definitions, examples, and supporting information\n   * **Emphasis:** Use `**bold text**` for important keywords, concepts, definitions, formulas, and key terms\n   * **Code/Algorithms:** Use code blocks when showing algorithms, formulas, or structured procedures\n   * **Examples:** Create dedicated example sections when demonstrating concepts\n\n4. **Content Organization Principles:**\n   * **Lead with Definitions:** Start major concepts with clear, complete definitions\n   * **Logical Progression:** Organize content from fundamental concepts to applications\n   * **Method Separation:** Create distinct sections for different approaches, methods, or procedures\n   * **Property Grouping:** List important characteristics and properties as organized bullet points\n   * **Step-by-Step Clarity:** Break down complex processes into clear, numbered or bulleted steps\n   * **Integration:** Weave transcript elaborations naturally into slide-based structure\n\n5. **Content Guidelines:**\n   * **Completeness:** Include all significant concepts mentioned in either source\n   * **Definitions:** Provide precise, academic definitions for key terms\n   * **Examples:** Include concrete examples with step-by-step demonstrations when provided\n   * **Analysis:** Add complexity analysis, efficiency discussions, or comparative analysis when mentioned\n   * **Context:** Include background information and applications discussed in the transcript\n   * **Clarifications:** Use transcript content to clarify or expand on slide points\n\n6. **Formatting Standards:**\n   * Use consistent indentation for nested bullet points\n   * Maintain parallel structure in lists and sections\n   * Include mathematical notation, formulas, or technical syntax using appropriate markdown\n   * Separate major sections with clear spacing\n   * Use descriptive, informative section headers\n   * Create logical flow between related concepts\n\n7. **Quality Requirements:**\n   * **Academic Tone:** Maintain formal, precise academic language\n   * **Comprehensiveness:** Include sufficient detail for thorough understanding\n   * **Clarity:** Make complex concepts accessible to students\n   * **Structure:** Ensure logical organization that supports learning\n   * **Integration:** Seamlessly combine slide and transcript information\n   * **Exam-Ready:** Provide the level of detail needed for assessment preparation\n\n8. **Adaptive Structure:** Let the content determine the specific sections, but commonly include:\n   * Fundamental definitions and concepts\n   * Key properties or characteristics  \n   * Different methods, approaches, or types\n   * Detailed examples and applications\n   * Comparative analysis or efficiency discussions\n   * Summary of key takeaways\n\n**Input Data:**\n\n{presentation_content}\n\n**Full Lecture Transcript:**\n\n```text\n{transcript_text}\n```\n\nGenerate comprehensive lecture notes in Markdown format following the above structure and requirements. Adapt the section organization to best fit the content while maintaining academic rigor and clarity. Start directly with the lecture title - no introductory text.\n\"\"\"\n\n# --- Enhanced Gemini API Function ---\ndef generate_notes_with_gemini(prompt_content, max_retries=2, initial_delay=5):\n    \"\"\"Calls the Gemini API using the initialized model, handles retries.\"\"\"\n    global model # Uses the genai.GenerativeModel instance from Step 7.1\n    if not model:\n        print(\"  Error: Gemini model not initialized.\")\n        return \"## Error: Gemini model not initialized.\"\n\n    delay = initial_delay\n    for attempt in range(max_retries + 1):\n        try:\n            # Make the API call with enhanced configuration\n            response = model.generate_content(\n                prompt_content,\n                generation_config={\n                    \"temperature\": 0.3,  # Lower temperature for more structured output\n                    \"top_p\": 0.9,\n                    \"top_k\": 40,\n                    \"max_output_tokens\": 8192,  # Increased for comprehensive notes\n                }\n            )\n\n            # Process the response\n            if not response.candidates:\n                block_reason = \"Unknown\"\n                try:\n                    block_reason = response.prompt_feedback.block_reason\n                except Exception:\n                    print(\"  Warning: Could not retrieve block_reason from prompt_feedback.\")\n\n                print(f\"  Warning: Call blocked by safety settings (Reason: {block_reason}). Attempt {attempt + 1}/{max_retries + 1}.\")\n                if attempt < max_retries:\n                    print(f\"   Retrying in {delay} seconds...\")\n                    time.sleep(delay)\n                    delay *= 2\n                    continue\n                else:\n                    return f\"## Error: Content generation blocked by safety settings (Reason: {block_reason}).\"\n\n            # Check if response text is usable\n            response_text = \"\"\n            try:\n                response_text = response.text\n            except ValueError:\n                print(f\"  Warning: ValueError accessing response.text. Prompt feedback: {response.prompt_feedback}\")\n                response_text = \"\"\n\n            if response_text and isinstance(response_text, str) and response_text.strip():\n                return response_text # Success\n            else:\n                print(f\"  Warning: Received empty text content from Gemini (Attempt {attempt + 1}/{max_retries + 1}).\")\n                try:\n                    print(f\"     Prompt Feedback: {response.prompt_feedback}\")\n                except Exception:\n                    print(\"     Could not retrieve prompt feedback.\")\n\n                if attempt < max_retries:\n                    print(f\"   Retrying in {delay} seconds...\")\n                    time.sleep(delay)\n                    delay *= 2\n                    continue\n                else:\n                    return \"## Error: Received empty response from Gemini.\"\n\n        except Exception as e:\n            print(f\"  Error during Gemini API call (Attempt {attempt + 1}/{max_retries + 1}): {type(e).__name__} - {e}\")\n            if attempt < max_retries:\n                print(f\"   Retrying in {delay} seconds...\")\n                time.sleep(delay)\n                delay *= 2\n                continue\n            else:\n                print(f\"  Failed after {max_retries} retries.\")\n                return f\"## Error: API call failed after retries ({type(e).__name__}).\"\n\n    return \"## Error: Failed to generate notes after multiple retries.\"\n\n# --- Chunked Processing Function ---\ndef generate_notes_with_chunking(transcript_text, formatted_presentation, lecture_title):\n    \"\"\"Generate notes using chunking approach for very long content.\"\"\"\n    print(\"    Using chunked processing for long content...\")\n    \n    # Generate outline first\n    outline_prompt = f\"\"\"\nBased on this lecture content, create an outline of 4-8 main sections for comprehensive lecture notes.\n\n**LECTURE:** {lecture_title}\n\n**SLIDES:**\n{formatted_presentation[:3000]}\n\n**TRANSCRIPT EXCERPT:**\n{transcript_text[:8000]}\n\nProvide ONLY a numbered list of section titles that cover the main topics discussed. Each title should be clear and descriptive.\nFormat: \n1. Section Title One\n2. Section Title Two\netc.\n\"\"\"\n    \n    outline_response = generate_notes_with_gemini(outline_prompt)\n    if outline_response.startswith(\"## Error:\"):\n        return outline_response\n    \n    # Parse section titles\n    section_titles = []\n    for line in outline_response.split('\\n'):\n        line = line.strip()\n        if line and any(char.isdigit() for char in line[:3]):\n            # Remove numbering and extract title\n            title = line.split('. ', 1)[-1] if '. ' in line else line\n            section_titles.append(title)\n    \n    if not section_titles:\n        return \"## Error: Could not generate valid section outline.\"\n    \n    # Chunk the transcript\n    transcript_chunks = chunk_text(transcript_text, max_tokens_per_chunk=8000, overlap_tokens=200)\n    print(f\"      Transcript split into {len(transcript_chunks)} chunks for {len(section_titles)} sections.\")\n    \n    # Generate content for each section\n    all_sections = []\n    chunk_per_section = max(1, len(transcript_chunks) // len(section_titles))\n    \n    for i, section_title in enumerate(section_titles):\n        start_chunk = min(i * chunk_per_section, len(transcript_chunks) - 1)\n        end_chunk = min(start_chunk + chunk_per_section + 1, len(transcript_chunks))\n        section_transcript = \"\\n\\n\".join(transcript_chunks[start_chunk:end_chunk])\n        \n        section_prompt = f\"\"\"\nCreate detailed content for this section of lecture notes:\n\n**SECTION:** {section_title}\n**LECTURE:** {lecture_title}\n\n**RELEVANT TRANSCRIPT:**\n{section_transcript[:12000]}\n\n**SLIDES FOR REFERENCE:**\n{formatted_presentation[:2000]}\n\nGenerate comprehensive content for this section using the formatting requirements:\n- Use ### for the section header: ### {section_title}\n- Use **bold** for key terms and concepts\n- Use * for bullet points with important details\n- Include definitions, examples, and explanations\n- Maintain academic tone and structure\n\nFocus only on content relevant to this section.\n\"\"\"\n        \n        section_response = generate_notes_with_gemini(section_prompt)\n        if not section_response.startswith(\"## Error:\"):\n            all_sections.append(section_response)\n        else:\n            all_sections.append(f\"### {section_title}\\n\\n*Error generating content for this section.*\")\n    \n    # Combine all sections\n    lecture_title_clean = lecture_title.replace('_', ' ').title()\n    combined_notes = f\"# Lecture Notes: {lecture_title_clean}\\n\\n\"\n    combined_notes += \"\\n\\n\".join(all_sections)\n    \n    return combined_notes\n\nprint(\"Enhanced helper functions and prompt template defined for Gemini.\")\n\n# ================================================================================\n\n# Step 7.2 - Cell 2 (Enhanced for Gemini): Main Note Generation Loop\n\nimport json\nfrom pathlib import Path\nimport time\nimport gc\n\n# *** Define the path to your pre-processed input data ***\nprocessed_input_path = Path(\"/kaggle/input/llm-hackathon/output\")\n# *** Output path remains the working directory ***\nfinal_notes_output_base = output_base_path # Defined previously (/kaggle/working/output)\n\n# Enhanced configuration\nMAX_SINGLE_CALL_LENGTH = 40000  # Character limit for single API call\nUSE_CHUNKING_FOR_LONG_CONTENT = True  # Enable chunking for very long transcripts\n\n# Initialize counters\ntotal_transcripts_processed_for_notes = 0\nsuccessful_notes_files = 0\nfailed_notes_files = 0\n\nprint(f\"\\n--- Starting Enhanced Lecture Note Generation (Gemini - Reading from: {processed_input_path}) ---\")\nprint(f\"--- Saving final notes to: {final_notes_output_base} ---\")\nprint(f\"--- Configuration: Max single call length: {MAX_SINGLE_CALL_LENGTH} chars, Chunking enabled: {USE_CHUNKING_FOR_LONG_CONTENT} ---\")\n\n# Iterate through subject folders in the PRE-PROCESSED input directory\nif not processed_input_path.exists():\n    print(f\"ERROR: Processed input path not found at {processed_input_path}\")\n    raise FileNotFoundError(f\"Processed input path not found: {processed_input_path}\")\n\nfor subject_dir in processed_input_path.iterdir():\n    if not subject_dir.is_dir():\n        continue\n\n    print(f\"\\nProcessing subject: {subject_dir.name}\")\n\n    # --- Load Presentation Data ---\n    presentation_data_dir = subject_dir / \"presentation_data\"\n    if not presentation_data_dir.exists():\n        print(f\"  Skipping subject {subject_dir.name}: No 'presentation_data' directory found.\")\n        continue\n    presentation_json_files = list(presentation_data_dir.glob('*.json'))\n    if not presentation_json_files:\n        print(f\"  Skipping subject {subject_dir.name}: No presentation JSON file found.\")\n        continue\n    presentation_json_path = presentation_json_files[0]\n    print(f\"  Using presentation data: {presentation_json_path.name}\")\n    try:\n        with open(presentation_json_path, 'r', encoding='utf-8') as f:\n            presentation_data = json.load(f)\n        formatted_presentation = format_presentation_data(presentation_data)\n        if \"error processing it\" in formatted_presentation:\n            print(f\"  Warning: Issue noted during formatting presentation data.\")\n    except Exception as e:\n        print(f\"  Error loading or formatting presentation JSON {presentation_json_path.name}: {e}\")\n        continue\n\n    # --- Find Transcript Files ---\n    transcript_dir = subject_dir / \"transcripts\"\n    if not transcript_dir.exists():\n        print(f\"  No 'transcripts' directory found for {subject_dir.name}.\")\n        continue\n    transcript_files = list(transcript_dir.glob('*.txt'))\n    if not transcript_files:\n        print(f\"  No transcript files found in {transcript_dir}.\")\n        continue\n\n    # --- Create Output Directory ---\n    output_notes_dir = final_notes_output_base / subject_dir.name / \"final_notes\"\n    output_notes_dir.mkdir(parents=True, exist_ok=True)\n\n    # --- Process Each Transcript File ---\n    for transcript_path in transcript_files:\n        total_transcripts_processed_for_notes += 1\n        print(f\"\\n  Processing transcript file: {transcript_path.relative_to(processed_input_path)}\")\n        output_note_path = output_notes_dir / f\"{transcript_path.stem}_notes.md\"\n\n        # --- Load Transcript Text ---\n        try:\n            with open(transcript_path, 'r', encoding='utf-8') as f:\n                full_content = f.read()\n                transcript_header = \"--- Full Transcript ---\"\n                header_index = full_content.find(transcript_header)\n                if header_index != -1:\n                    text_start_index = full_content.find('\\n', header_index) + 1\n                    timestamp_marker = \"\\n\\n--- Timestamps\"\n                    timestamp_index = full_content.find(timestamp_marker, text_start_index)\n                    transcript_text = full_content[text_start_index:timestamp_index].strip() if timestamp_index != -1 else full_content[text_start_index:].strip()\n                else:\n                    transcript_text = full_content.strip()\n            \n            if not transcript_text:\n                print(\"    Warning: Transcript file is empty. Skipping file.\")\n                continue\n                \n        except Exception as e:\n            print(f\"    Error loading transcript {transcript_path.name}: {e}\")\n            failed_notes_files += 1\n            continue\n\n        # --- Determine Processing Strategy ---\n        total_content_length = len(transcript_text) + len(formatted_presentation)\n        print(f\"    Total content length: {total_content_length:,} characters\")\n        \n        use_chunking = (USE_CHUNKING_FOR_LONG_CONTENT and \n                       total_content_length > MAX_SINGLE_CALL_LENGTH)\n        \n        if use_chunking:\n            print(f\"    Content exceeds {MAX_SINGLE_CALL_LENGTH:,} chars - using chunked approach\")\n        else:\n            print(f\"    Using single comprehensive API call\")\n\n        # --- Generate Notes ---\n        start_time = time.time()\n        \n        if use_chunking:\n            # Use chunked approach for very long content\n            generated_notes = generate_notes_with_chunking(\n                transcript_text, formatted_presentation, transcript_path.stem\n            )\n        else:\n            # Use single comprehensive call\n            final_prompt = prompt_template.format(\n                presentation_content=formatted_presentation,\n                transcript_text=transcript_text\n            )\n            print(f\"    Calling LLM ({llm_model_name}) for full transcript...\")\n            generated_notes = generate_notes_with_gemini(final_prompt)\n        \n        end_time = time.time()\n\n        # --- Process Result and Save ---\n        if generated_notes and not generated_notes.strip().startswith(\"## Error:\"):\n            print(f\"      Note generation successful (took {end_time - start_time:.2f}s).\")\n            try:\n                # Don't duplicate the title if it's already included\n                if generated_notes.strip().startswith(\"# Lecture Notes:\"):\n                    final_output = generated_notes\n                else:\n                    final_output = f\"# Lecture Notes: {transcript_path.stem}\\n\\n{generated_notes}\"\n                \n                with open(output_note_path, 'w', encoding='utf-8') as f:\n                    f.write(final_output)\n                print(f\"    Saved notes to: {output_note_path.relative_to(Path('/kaggle/working/'))}\")\n                successful_notes_files += 1\n            except Exception as e:\n                print(f\"    Error saving notes to {output_note_path.name}: {e}\")\n                failed_notes_files += 1\n        else:\n            print(f\"      Note generation failed or returned error (took {end_time - start_time:.2f}s).\")\n            failed_notes_files += 1\n            try:\n                error_output = f\"# Lecture Notes: {transcript_path.stem}\\n\\n{generated_notes}\"\n                with open(output_note_path, 'w', encoding='utf-8') as f:\n                    f.write(error_output)\n                print(f\"    Saved error message to: {output_note_path.relative_to(Path('/kaggle/working/'))}\")\n            except Exception as e:\n                print(f\"    Error saving error message to {output_note_path.name}: {e}\")\n\n        gc.collect() # Garbage collect after each file\n\nprint(\"\\n--- Enhanced Note Generation Loop (Gemini) Finished ---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:48:57.588955Z","iopub.execute_input":"2025-06-23T10:48:57.589234Z","iopub.status.idle":"2025-06-23T10:57:15.236879Z","shell.execute_reply.started":"2025-06-23T10:48:57.589214Z","shell.execute_reply":"2025-06-23T10:57:15.236175Z"}},"outputs":[{"name":"stdout","text":"Enhanced helper functions and prompt template defined for Gemini.\n\n--- Starting Enhanced Lecture Note Generation (Gemini - Reading from: /kaggle/input/llm-hackathon/output) ---\n--- Saving final notes to: /kaggle/working/output ---\n--- Configuration: Max single call length: 40000 chars, Chunking enabled: True ---\n\nProcessing subject: stable_diffusion\n  Using presentation data: Stable Diffusion_content.json\n\n  Processing transcript file: stable_diffusion/transcripts/19853_shylaja.sharath_31_20250327084200249_Video_ENC.txt\n    Total content length: 61,157 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 47.84s).\n    Saved notes to: output/stable_diffusion/final_notes/19853_shylaja.sharath_31_20250327084200249_Video_ENC_notes.md\n\n  Processing transcript file: stable_diffusion/transcripts/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1).txt\n    Total content length: 47,326 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 1 chunks for 8 sections.\n      Note generation successful (took 47.13s).\n    Saved notes to: output/stable_diffusion/final_notes/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1)_notes.md\n\nProcessing subject: Lora&Qlora\n  Using presentation data: Finetuning_content.json\n\n  Processing transcript file: Lora&Qlora/transcripts/19853_shylaja.sharath_31_20250318112700094_Video_ENC (1).txt\n    Total content length: 50,825 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 49.94s).\n    Saved notes to: output/Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318112700094_Video_ENC (1)_notes.md\n\n  Processing transcript file: Lora&Qlora/transcripts/19853_shylaja.sharath_31_20250318121200085_Video_ENC (1).txt\n    Total content length: 49,960 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 49.59s).\n    Saved notes to: output/Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318121200085_Video_ENC (1)_notes.md\n\n  Processing transcript file: Lora&Qlora/transcripts/19853_shylaja.sharath_31_20250318125700082_Video_ENC.txt\n    Total content length: 25,599 characters\n    Using single comprehensive API call\n    Calling LLM (gemini-1.5-flash-latest) for full transcript...\n      Note generation successful (took 10.30s).\n    Saved notes to: output/Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318125700082_Video_ENC_notes.md\n\nProcessing subject: expn_tree\n  Using presentation data: Class7_Unit3_Trees_ExprTree_content.json\n\n  Processing transcript file: expn_tree/transcripts/7a_2020-09-24 09-28-52_ExprTreeCon.txt\n    Total content length: 39,152 characters\n    Using single comprehensive API call\n    Calling LLM (gemini-1.5-flash-latest) for full transcript...\n      Note generation successful (took 9.58s).\n    Saved notes to: output/expn_tree/final_notes/7a_2020-09-24 09-28-52_ExprTreeCon_notes.md\n\n  Processing transcript file: expn_tree/transcripts/7b_2020-09-25 12-12-37_ExprTReeCode 00_00_09-00_26_52.txt\n    Total content length: 25,577 characters\n    Using single comprehensive API call\n    Calling LLM (gemini-1.5-flash-latest) for full transcript...\n      Note generation successful (took 9.29s).\n    Saved notes to: output/expn_tree/final_notes/7b_2020-09-25 12-12-37_ExprTReeCode 00_00_09-00_26_52_notes.md\n\nProcessing subject: agentic\n  Using presentation data: Agentic Workflow_content.json\n\n  Processing transcript file: agentic/transcripts/19853_shylaja.sharath_31_20250401121200417_Video_ENC.txt\n    Total content length: 51,589 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 47.88s).\n    Saved notes to: output/agentic/final_notes/19853_shylaja.sharath_31_20250401121200417_Video_ENC_notes.md\n\nProcessing subject: Heap\n  Using presentation data: Class8_Unit3_Trees_Heap_content.json\n\n  Processing transcript file: Heap/transcripts/8a_2020-09-24 13-07-04_HeapCon 00_00_01-00_42_121.txt\n    Total content length: 41,400 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 48.69s).\n    Saved notes to: output/Heap/final_notes/8a_2020-09-24 13-07-04_HeapCon 00_00_01-00_42_121_notes.md\n\n  Processing transcript file: Heap/transcripts/8b_2020-09-26 09-34-27_HeapCode 00_00_09-00_56_50.txt\n    Total content length: 45,850 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 58.10s).\n    Saved notes to: output/Heap/final_notes/8b_2020-09-26 09-34-27_HeapCode 00_00_09-00_56_50_notes.md\n\nProcessing subject: BST\n  Using presentation data: Class2_Unit3_Tree_BST_DynamicInsert_content.json\n  No 'transcripts' directory found for BST.\n\nProcessing subject: TBT\n  Using presentation data: Class6_Unit3_Trees_ThreadBST_content.json\n\n  Processing transcript file: TBT/transcripts/6b_2020-09-25 11-29-19_TBTCode 00_00_04-00_35_198.txt\n    Total content length: 30,989 characters\n    Using single comprehensive API call\n    Calling LLM (gemini-1.5-flash-latest) for full transcript...\n      Note generation successful (took 9.06s).\n    Saved notes to: output/TBT/final_notes/6b_2020-09-25 11-29-19_TBTCode 00_00_04-00_35_198_notes.md\n\n  Processing transcript file: TBT/transcripts/6a_2020-09-22 09-49-32_TBTCon.txt\n    Total content length: 29,032 characters\n    Using single comprehensive API call\n    Calling LLM (gemini-1.5-flash-latest) for full transcript...\n      Note generation successful (took 10.06s).\n    Saved notes to: output/TBT/final_notes/6a_2020-09-22 09-49-32_TBTCon_notes.md\n\nProcessing subject: Multimodal\n  Using presentation data: MAMBA_content.json\n\n  Processing transcript file: Multimodal/transcripts/19853_shylaja.sharath_31_20250401112700078_Video_ENC.txt\n    Total content length: 57,496 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 43.14s).\n    Saved notes to: output/Multimodal/final_notes/19853_shylaja.sharath_31_20250401112700078_Video_ENC_notes.md\n\nProcessing subject: binary_tree_traversal\n  Using presentation data: Class5_Unit3_BST_Traversal_content.json\n\n  Processing transcript file: binary_tree_traversal/transcripts/5a_2020-09-15 09-04-51_BinTraversal.txt\n    Total content length: 50,913 characters\n    Content exceeds 40,000 chars - using chunked approach\n    Using chunked processing for long content...\n      Transcript split into 2 chunks for 8 sections.\n      Note generation successful (took 46.48s).\n    Saved notes to: output/binary_tree_traversal/final_notes/5a_2020-09-15 09-04-51_BinTraversal_notes.md\n\nProcessing subject: Tree_traversal\n  Using presentation data: class9_Unit3_Trees_naryTraversal_content.json\n\n  Processing transcript file: Tree_traversal/transcripts/9a_2020-09-16 09-46-13_TreeTravCon.txt\n    Total content length: 20,356 characters\n    Using single comprehensive API call\n    Calling LLM (gemini-1.5-flash-latest) for full transcript...\n      Note generation successful (took 9.14s).\n    Saved notes to: output/Tree_traversal/final_notes/9a_2020-09-16 09-46-13_TreeTravCon_notes.md\n\n--- Enhanced Note Generation Loop (Gemini) Finished ---\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Step 7.2 - Cell 3: Summary and Verification\n\nprint(\"\\n--- Note Generation Summary ---\")\nprint(f\"Total transcripts found for processing: {total_transcripts_processed_for_notes}\")\nprint(f\"Successfully generated notes files: {successful_notes_files}\")\nprint(f\"Failed notes files (inc. chunk errors, load/save errors): {failed_notes_files}\")\n\n# Optional: Verify by listing some output note files\nif successful_notes_files > 0:\n    print(\"\\nExample output note files (.md):\")\n    example_count = 0\n    for subject_dir in final_notes_output_base.iterdir():\n        notes_data_dir = subject_dir / \"final_notes\"\n        if subject_dir.is_dir() and notes_data_dir.exists():\n            for note_file in notes_data_dir.iterdir():\n                if note_file.suffix == '.md' and example_count < 5:\n                    print(f\"- {note_file.relative_to(final_notes_output_base)}\")\n                    example_count += 1\n            if example_count >= 5:\n                break\n    if example_count == 0:\n        print(\"Could not find any example .md files in the output final_notes directories.\")\n\n# Additional verification: Show file sizes\nif successful_notes_files > 0:\n    print(\"\\nFile size verification:\")\n    total_size = 0\n    file_count = 0\n    for subject_dir in final_notes_output_base.iterdir():\n        notes_data_dir = subject_dir / \"final_notes\"\n        if subject_dir.is_dir() and notes_data_dir.exists():\n            for note_file in notes_data_dir.iterdir():\n                if note_file.suffix == '.md':\n                    size_kb = note_file.stat().st_size / 1024\n                    total_size += size_kb\n                    file_count += 1\n    \n    if file_count > 0:\n        avg_size = total_size / file_count\n        print(f\"Average note file size: {avg_size:.1f} KB\")\n        print(f\"Total notes size: {total_size:.1f} KB\")\n\nprint(\"\\n--- Processing Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T10:57:15.238001Z","iopub.execute_input":"2025-06-23T10:57:15.238276Z","iopub.status.idle":"2025-06-23T10:57:15.246522Z","shell.execute_reply.started":"2025-06-23T10:57:15.238252Z","shell.execute_reply":"2025-06-23T10:57:15.245786Z"}},"outputs":[{"name":"stdout","text":"\n--- Note Generation Summary ---\nTotal transcripts found for processing: 15\nSuccessfully generated notes files: 15\nFailed notes files (inc. chunk errors, load/save errors): 0\n\nExample output note files (.md):\n- agentic/final_notes/19853_shylaja.sharath_31_20250401121200417_Video_ENC_notes.md\n- Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318125700082_Video_ENC_notes.md\n- Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318112700094_Video_ENC (1)_notes.md\n- Lora&Qlora/final_notes/19853_shylaja.sharath_31_20250318121200085_Video_ENC (1)_notes.md\n- stable_diffusion/final_notes/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1)_notes.md\n\nFile size verification:\nAverage note file size: 20.1 KB\nTotal notes size: 301.3 KB\n\n--- Processing Complete ---\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}